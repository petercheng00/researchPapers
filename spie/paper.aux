\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{liu2010indoor}
\citation{chen2010indoor,liu2010indoor,kua2012loopclosure}
\citation{sanchez2012point}
\citation{liu2010indoor}
\citation{chen2010indoor,liu2010indoor,kua2012loopclosure}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction\relax }{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Simple Texture Mapping}{1}{section.2}}
\newlabel{sec:simpleTextureMapping}{{2}{1}{Simple Texture Mapping\relax }{section.2}{}}
\citation{rayintersection}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Surfaces to be textured are specified in 3D space by corners $C_i$. Images are related to each surface through the camera matrices $P_{1..m}$. \relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:projection}{{1}{2}{Surfaces to be textured are specified in 3D space by corners $C_i$. Images are related to each surface through the camera matrices $P_{1..m}$. \relax \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces We minimize camera angle $\alpha $ and distance $d$ by maximizing the scoring function $\frac  {1}{d} (-1 \cdot \mathaccentV {vec}17E{c}) \cdot \mathaccentV {vec}17E{n}$\relax }}{2}{figure.caption.2}}
\newlabel{fig:scoringFunction}{{2}{2}{We minimize camera angle $\alpha $ and distance $d$ by maximizing the scoring function $\frac {1}{d} (-1 \cdot \vec {c}) \cdot \vec {n}$\relax \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Tile-based Texture Mapping}{2}{subsection.2.1}}
\newlabel{sec:tileBasedMapping}{{2.1}{2}{Tile-based Texture Mapping\relax }{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a): Tile-based texturing. (b): Tile-based texturing after image alignment. (c): Tile-based texturing after image alignment with caching. (d): Shortest path texturing after image alignment). (e,f): Blending applied to (c) and (d). (g,h): Zoomed in views of discontinuities in (e) vs. in (f).\relax }}{3}{figure.caption.3}}
\newlabel{fig:compareAll}{{3}{3}{(a): Tile-based texturing. (b): Tile-based texturing after image alignment. (c): Tile-based texturing after image alignment with caching. (d): Shortest path texturing after image alignment). (e,f): Blending applied to (c) and (d). (g,h): Zoomed in views of discontinuities in (e) vs. in (f).\relax \relax }{figure.caption.3}{}}
\citation{szeliski2006image}
\citation{liu2010indoor}
\citation{panorama2d,autostitch}
\citation{kua2012loopclosure,sanchez2012point}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Texture alignment via (a) the graph-based localization refinement algorithm, (b) the AutoStitch software package, and (c) our method.\relax }}{4}{figure.caption.4}}
\newlabel{fig:mosaic3D}{{4}{4}{Texture alignment via (a) the graph-based localization refinement algorithm, (b) the AutoStitch software package, and (c) our method.\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Existing Approaches to Image Alignment}{4}{section.3}}
\newlabel{sec:existingApproaches}{{3}{4}{Existing Approaches to Image Alignment\relax }{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}2d Image Alignment}{4}{section.4}}
\newlabel{sec:2dAlignment}{{4}{4}{2d Image Alignment\relax }{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces (a) Lines detected in image projections via Hough transform. (b) In this example, we project two images at once for the sake of demonstration. Red line segments represent where surfaces intersect, and green line segments are line segments detected in the image. Above are the original projections using input camera poses, and below are the projections after rotation and translation for alignment.\relax }}{5}{figure.caption.5}}
\newlabel{fig:geometryAlignment}{{5}{5}{(a) Lines detected in image projections via Hough transform. (b) In this example, we project two images at once for the sake of demonstration. Red line segments represent where surfaces intersect, and green line segments are line segments detected in the image. Above are the original projections using input camera poses, and below are the projections after rotation and translation for alignment.\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Geometry-based Alignment}{5}{subsection.4.1}}
\newlabel{sec:geometryAlignment}{{4.1}{5}{Geometry-based Alignment\relax }{subsection.4.1}{}}
\citation{fischler1981random}
\citation{lowe1999object,mikolajczyk2005performance,szeliski2006image}
\citation{siftgpu}
\citation{fischler1981random}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Image Occlusion}{6}{subsection.4.2}}
\newlabel{sec:imageOcclusion}{{4.2}{6}{Image Occlusion\relax }{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}2D Feature Alignment}{6}{subsection.4.3}}
\newlabel{sec:robustSIFTFeatureMatching}{{4.3}{6}{2D Feature Alignment\relax }{subsection.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Image Compositing}{7}{section.5}}
\newlabel{sec:imageCompositing}{{5}{7}{Image Compositing\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Tile-Mapping with Caching}{7}{subsection.5.1}}
\newlabel{sec:mappingWithCaching}{{5.1}{7}{Tile-Mapping with Caching\relax }{subsection.5.1}{}}
\citation{dijkstra}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Images for vertical planes are tilted, but their camera axes are more or less normal to their respective planes. (b) Camera axes for ceiling images are at large angles with respect to plane normals. (c) Wall images are cropped to be rectangular.\relax }}{8}{figure.caption.6}}
\newlabel{fig:projectionAngles}{{6}{8}{(a) Images for vertical planes are tilted, but their camera axes are more or less normal to their respective planes. (b) Camera axes for ceiling images are at large angles with respect to plane normals. (c) Wall images are cropped to be rectangular.\relax \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces DAG construction for the image selection process.  \relax }}{8}{figure.caption.7}}
\newlabel{fig:dagCreation}{{7}{8}{DAG construction for the image selection process. \\\relax \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Shortest Path Texturing}{8}{subsection.5.2}}
\newlabel{sec:shortestPath}{{5.2}{8}{Shortest Path Texturing\relax }{subsection.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Blending}{9}{subsection.5.3}}
\newlabel{sec:blending}{{5.3}{9}{Blending\relax }{subsection.5.3}{}}
\citation{openscenegraph}
\citation{linebased,rectangularstructures}
\citation{linearposeestimation}
\bibdata{report}
\bibcite{liu2010indoor}{1}
\bibcite{chen2010indoor}{2}
\bibcite{kua2012loopclosure}{3}
\bibcite{sanchez2012point}{4}
\bibcite{rayintersection}{5}
\bibcite{szeliski2006image}{6}
\bibcite{panorama2d}{7}
\bibcite{autostitch}{8}
\bibcite{fischler1981random}{9}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results and Conclusions}{10}{section.6}}
\newlabel{sec:resultsAndConclusions}{{6}{10}{Results and Conclusions\relax }{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Future Work}{10}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Examples of our final texture mapping output for (a) walls, (b) ceilings, (c) floors, (d) full models.\relax }}{11}{figure.caption.8}}
\newlabel{fig:results}{{8}{11}{Examples of our final texture mapping output for (a) walls, (b) ceilings, (c) floors, (d) full models.\relax \relax }{figure.caption.8}{}}
\bibcite{lowe1999object}{10}
\bibcite{mikolajczyk2005performance}{11}
\bibcite{siftgpu}{12}
\bibcite{dijkstra}{13}
\bibcite{openscenegraph}{14}
\bibcite{linebased}{15}
\bibcite{rectangularstructures}{16}
\bibcite{linearposeestimation}{17}
\bibstyle{spiebib}
