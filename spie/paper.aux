\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{liu2010indoor}
\citation{chen2010indoor,liu2010indoor,kua2012loopclosure}
\citation{sanchez2012point}
\citation{liu2010indoor}
\citation{chen2010indoor,liu2010indoor,kua2012loopclosure}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction\relax }{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Simple Texture Mapping}{1}{section.2}}
\newlabel{sec:simpleTextureMapping}{{2}{1}{Simple Texture Mapping\relax }{section.2}{}}
\citation{rayintersection}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Surfaces to be textured are specified in 3D space by corners $C_i$. Images are related to each surface through the camera matrics $P_{1..m}$. \relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:projection}{{1}{2}{Surfaces to be textured are specified in 3D space by corners $C_i$. Images are related to each surface through the camera matrics $P_{1..m}$. \relax \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces We minimize camera angle $\alpha $ and distance $d$ by maximizing the scoring function $\frac  {1}{d} (-1 \cdot \mathaccentV {vec}17E{c}) \cdot \mathaccentV {vec}17E{n}$\relax }}{2}{figure.caption.2}}
\newlabel{fig:scoringFunction}{{2}{2}{We minimize camera angle $\alpha $ and distance $d$ by maximizing the scoring function $\frac {1}{d} (-1 \cdot \vec {c}) \cdot \vec {n}$\relax \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Tile-based Texture Mapping}{2}{subsection.2.1}}
\newlabel{sec:tileBasedMapping}{{2.1}{2}{Tile-based Texture Mapping\relax }{subsection.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Existing Approaches to Image Alignment}{2}{section.3}}
\newlabel{sec:existingApproaches}{{3}{2}{Existing Approaches to Image Alignment\relax }{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a): Tile-based texturing. (b): Tile-based texturing after image alignment. (c): Tile-based texturing after image alignment with caching. (d): Shortest path texturing after image alignment). (e,f): Comparison of image artifacts in (c) vs. (d). (g,h): Blending applied to (c) and (d).\relax }}{3}{figure.caption.3}}
\newlabel{fig:compareAll}{{3}{3}{(a): Tile-based texturing. (b): Tile-based texturing after image alignment. (c): Tile-based texturing after image alignment with caching. (d): Shortest path texturing after image alignment). (e,f): Comparison of image artifacts in (c) vs. (d). (g,h): Blending applied to (c) and (d).\relax \relax }{figure.caption.3}{}}
\citation{szeliski2006image}
\citation{liu2010indoor}
\citation{panorama2d,autostitch}
\citation{kua2012loopclosure,sanchez2012point}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Texture alignment via (a) the graph-based localization refinement algorithm, (b) the AutoStitch software package, and (c) our method.\relax }}{4}{figure.caption.4}}
\newlabel{fig:mosaic3D}{{4}{4}{Texture alignment via (a) the graph-based localization refinement algorithm, (b) the AutoStitch software package, and (c) our method.\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}2D Image Alignment}{4}{section.4}}
\newlabel{sec:2dAlignment}{{4}{4}{2D Image Alignment\relax }{section.4}{}}
\citation{fischler1981random}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces (a) When texturing the red surface, it makes sense to align images to surface boundaries and intersections with other surfaces. (b) In this example, we project two images at once for the sake of demonstration, where the red lines are geometry-based lines where surfaces intersect, and the green ines are lines detected in the image via Hough transform. Above are the original projections using input camera poses, and below are the projections after rotation and translation for alignment.\relax }}{5}{figure.caption.5}}
\newlabel{fig:geometryAlignment}{{5}{5}{(a) When texturing the red surface, it makes sense to align images to surface boundaries and intersections with other surfaces. (b) In this example, we project two images at once for the sake of demonstration, where the red lines are geometry-based lines where surfaces intersect, and the green ines are lines detected in the image via Hough transform. Above are the original projections using input camera poses, and below are the projections after rotation and translation for alignment.\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Geometry-based Alignment}{5}{subsection.4.1}}
\newlabel{sec:geometryAlignment}{{4.1}{5}{Geometry-based Alignment\relax }{subsection.4.1}{}}
\citation{lowe1999object,mikolajczyk2005performance,szeliski2006image}
\citation{siftgpu}
\citation{fischler1981random}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Image Occlusion}{6}{subsection.4.2}}
\newlabel{sec:imageOcclusion}{{4.2}{6}{Image Occlusion\relax }{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}2D Feature Alignment}{6}{subsection.4.3}}
\newlabel{sec:robustSIFTFeatureMatching}{{4.3}{6}{2D Feature Alignment\relax }{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Images for vertical planes are tilted, but their camera axes are more or less normal to their respective planes. (b) Camera axes for ceiling images are at large angles with respect to plane normals. (c) Wall images are cropped to be rectangular.\relax }}{7}{figure.caption.6}}
\newlabel{fig:projectionAngles}{{6}{7}{(a) Images for vertical planes are tilted, but their camera axes are more or less normal to their respective planes. (b) Camera axes for ceiling images are at large angles with respect to plane normals. (c) Wall images are cropped to be rectangular.\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Image Compositing}{7}{section.5}}
\newlabel{sec:imageCompositing}{{5}{7}{Image Compositing\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Tile-Mapping with Caching}{7}{subsection.5.1}}
\newlabel{sec:mappingWithCaching}{{5.1}{7}{Tile-Mapping with Caching\relax }{subsection.5.1}{}}
\citation{dijkstra}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces DAG construction for the image selection process.  \relax }}{8}{figure.caption.7}}
\newlabel{fig:dagCreation}{{7}{8}{DAG construction for the image selection process. \\\relax \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Shortest Path Texturing}{8}{subsection.5.2}}
\newlabel{sec:shortestPath}{{5.2}{8}{Shortest Path Texturing\relax }{subsection.5.2}{}}
\citation{openscenegraph}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Blending}{9}{subsection.5.3}}
\newlabel{sec:blending}{{5.3}{9}{Blending\relax }{subsection.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results and Conclusions}{9}{section.6}}
\newlabel{sec:resultsAndConclusions}{{6}{9}{Results and Conclusions\relax }{section.6}{}}
\bibdata{report}
\bibcite{liu2010indoor}{1}
\bibcite{chen2010indoor}{2}
\bibcite{kua2012loopclosure}{3}
\bibcite{sanchez2012point}{4}
\bibcite{rayintersection}{5}
\bibcite{szeliski2006image}{6}
\bibcite{panorama2d}{7}
\bibcite{autostitch}{8}
\bibcite{fischler1981random}{9}
\bibcite{lowe1999object}{10}
\bibcite{mikolajczyk2005performance}{11}
\bibcite{siftgpu}{12}
\bibcite{dijkstra}{13}
\bibcite{openscenegraph}{14}
\bibstyle{spiebib}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Examples of our final texture mapping output for (a) walls, (b) ceilings, (c) floors, (d) full models.\relax }}{11}{figure.caption.8}}
\newlabel{fig:results}{{8}{11}{Examples of our final texture mapping output for (a) walls, (b) ceilings, (c) floors, (d) full models.\relax \relax }{figure.caption.8}{}}
