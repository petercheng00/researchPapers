%  article.tex (Version 3.3, released 19 January 2008)
%  Article to demonstrate format for SPIE Proceedings
%  Special instructions are included in this file after the
%  symbol %>>>>
%  Numerous commands are commented out, but included to show how
%  to effect various options, e.g., to print page numbers, etc.
%  This LaTeX source file is composed for LaTeX2e.

%  The following commands have been added in the SPIE class 
%  file (spie.cls) and will not be understood in other classes:
%  \supit{}, \authorinfo{}, \skiplinehalf, \keywords{}
%  The bibliography style file is called spiebib.bst, 
%  which replaces the standard style unstr.bst.  

\documentclass[]{spie}  %>>> use for US letter paper
%%\documentclass[a4paper]{spie}  %>>> use this instead for A4 paper
%%\documentclass[nocompress]{spie}  %>>> to avoid compression of citations
%% \addtolength{\voffset}{9mm}   %>>> moves text field down
%% \renewcommand{\baselinestretch}{1.65}   %>>> 1.65 for double spacing, 1.25 for 1.5 spacing 
%  The following command loads a graphics package to include images 
%  in the document. It may be necessary to specify a DVI driver option,
%  e.g., [dvips], but that may be inappropriate for some LaTeX 
%  installations. 
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\title{Texture mapping 3D planar models of indoor environments with noisy camera poses} 

%>>>> The author is responsible for formatting the 
%  author list and their institutions.  Use  \skiplinehalf 
%  to separate author list from addresses and between each address.
%  The correspondence between each author and his/her address
%  can be indicated with a superscript in italics, 
%  which is easily obtained with \supit{}.

\author{Peter Cheng, Michael Anderson, Stewart He, Avideh Zakhor
\skiplinehalf
University of California, Berkeley\\
}

 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%>>>> uncomment following for page numbers
% \pagestyle{plain}    
%>>>> uncomment following to start page numbering at 301 
%\setcounter{page}{301} 
 
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{abstract}
  Automated 3D modeling of building interiors is used in applications
  such as virtual reality and environment mapping. Texturing these
  models allows for photorealistic visualizations of the data
  collected by such modeling systems. Camera poses obtained by these
  systems and used for texturing often suffer from inaccuracies
  however, resulting in visible discontinuities when successive images
  are projected onto a surface for texturing. Existing methods to
  stitch images together are often computationally expensive and work
  independently of pose estimates and geometry information. Using data
  from a human-operated backpack system, we propose an efficient
  method to refine camera poses in 2D using both existing estimates
  and geometry information, followed by two different methods to
  composite images together, based on the geometry of surfaces being
  textured. The effectiveness of our methods is demonstrated on a
  number of different indoor environments.
\end{abstract}

% >>>> Include a list of keywords after the abstract

\keywords{Texture Mapping, Reconstruction, Image Stitching, Mosaicing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}
Three-dimensional modeling of indoor environments has a variety of
applications in fields such as architecture, conservation, and
simulation. Applying accurate textures to these models is important in
adding context to digital visualizations, and allows for image-based
analysis of environments. In this paper, we perform data acquisition
with a backpack-mounted system carried by an ambulatory human. This
backpack system contains a series of laser scanners and inertial
measurement units, allowing it to solve the simultaneous localization
and mapping (SLAM) problem, which produces backpack poses over time as
well as a point cloud representing the surrounding environment. For
environment geometry, we work with models obtained by fitting
low-resolution planar surfaces to these point clouds.  While a
human-carried system provides advantages over more common
wheel-mounted systems in terms of agility and portability, it often
leads to relatively high localization error even after applying
sophisticated localization techniques. Furthermore, our model geometry
usually contains some error as well, and is often tuned to ignore
low-resolution features, such as small walls, furniture, and other
small non-planar features commonly found in indoor environments. As a
result, methods for texture mapping that rely on accurate camera poses
and projection surfaces generally produce poor results.

Our goal of texturing planar surfaces with misaligned camera poses
straddles a number of highly-researched fields, including image
stitching, panorama generation, and image-based localization
algorithims. We will examine the results of two existing approaches
from these fields of study in Section X, and compare them with our
approach, which utilizes several unique aspects of our modeling system
and input data.

The remainder of the paper is organized as follows. Section X
demonstrates 2 existing image stitching algorithms on our
datasets. Section X explains how images are projected onto our
geometry, and a simple approach towards texturing. Section X contains
our approach towards image alignment, followed by Section X, which
describes our two methods of compositing images. Section X contains
results and conclusions.

\section{Existing Approaches}
Stitching together multiple images to produce a larger image is a
commonly performed task, with many successful approaches over the past
years. Generally, parts of images are first matched to eachother,
usually through direct comparisons or feature detection and
matching. Images are then transformed to maximize matches, often by
calculating homographies between pairs of images, or by modifying
camera poses in 1 to 6 degrees of freedom.

Feature matching has a number of advantages over direct matching that
make it more suitable for our data, which is X. Feature matching
however, works best when multiple unique visual references exist in the
environment that can be detected in multiple images. In contrast, our
indoor environments have a high prevalence of bare surfaces, as well
as repeating textures that cause difficulty in disambiguating
features. This lack of reliable reference points often results in
errors when matching images together.

Additionally, our datasets often contain long chains of images, which
leads to error accumulation when image correspondences are not
exact. For example, when matching a long chain of images through
homographies, a pixel in the $nth$ image is translated into the first
image's coordinates by multiplying by the $3\times3$ matrices $H_1 H_2
H_3 ... H_n$. Errors in any of these homography matrices are
propagated to all further images, resulting in drift.

Past work with our data acquisition backpack integrated image
stitching with localization algorithms, and performed homography-based
alignment. As described above, this often resulted in drift, as shown in Figure X. This approach is also tied into a localization
algorithm, and its iterative camera adjustment process over our large
datasets leads to prohibitively long runtime.

Drift during image stitching can be combated using X. The AutoStitch software package
contains X. Though AutoStitch performs well in areas with dense
features, it can not handle even short segments of bare walls. The example in Figure X was generated after manual tuning, and areas with fewer visual
features or repeating texture patterns simply failed outright with AutoStitch.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% References %%%%%

\bibliography{report} %>>>> bibliography data in report.bib
\bibliographystyle{spiebib} %>>>> makes bibtex use spiebib.bst

\end{document} 
